{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello and congrats on the phd!!\n",
    "This notebook will help you streamline your graduation photo according to the rest of team VAP-lab. The code should be light weight, with the exception of the inpainting tool, which is voluntary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to install the requirements. Please make sure you have conda installed and run the following commands in *your terminal* and make sure your notebook is running on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3265784366.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    conda env create -f environment.yml\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## RRun in terminal, not in notebook \n",
    "conda env create -f environment.yml\n",
    "conda activate phd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running cells in the notebook, you should run them through the newly created 'phd' kernel. You may verify that you are running the notebook in the correct environment if the following code outputs an environment at location \"envs/phd\". \n",
    "\n",
    "If the environemnt is not available, try shutting down you editor and opening it again (you just got a PhD, and we still resolve to turning this on and off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/vap/miniconda3/envs/phd:\n"
     ]
    }
   ],
   "source": [
    "! conda list | grep \"packages in environment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things smoother, please help define the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"Someone clever\" # As you would want on your poster\n",
    "phd_title = \"Something very smart and very groundbreaking\"\n",
    "date_of_graduation = \"DD-MM-YYYY\" # format: DD-MM-YYYY\n",
    "path_to_image = \"Pictures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook contains methods for \n",
    "- Cropping the image\n",
    "- Removing background (although we recommend using www.remove.bg for complex cases)\n",
    "\n",
    "- Inpainting for creating missing details or removing various items (voluntary)\n",
    "\n",
    "And finally creating the actual pdf which will go on the Wall of Fame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "Please run the cells below to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os, re\n",
    "from PIL import Image, ImageOps\n",
    "import tkinter as tk # for UIs *\n",
    "import cv2 # for face detection\n",
    "\n",
    "def resize_wrt_ratio(img, desired_height): \n",
    "    ratio = img.width/img.height\n",
    "\n",
    "    img = img.resize((int(desired_height*ratio), desired_height))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching folder at /home/vap/Documents/poster-generator/Pictures/ for photo of Someone clever\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSearching folder at \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m for photo of \u001b[39m\u001b[39m{\u001b[39;00myour_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     filename \u001b[39m=\u001b[39m [filename \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(path) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(re\u001b[39m.\u001b[39mescape(name) \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m, filename, re\u001b[39m.\u001b[39mIGNORECASE)][\u001b[39m0\u001b[39m] \u001b[39m# we use first occurence of name\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m as reference photo\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIf you want a different image used, please specify \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m\u001b[39m variable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "name = your_name.replace(\" \", \"\").lower()\n",
    "path = path_to_image\n",
    "filename = \"\"\n",
    "\n",
    "\n",
    "if type(path) == type(None) or path == \"\":\n",
    "    print(f\"Searching current folder for photo of {your_name}\")\n",
    "else: \n",
    "    path = os.getcwd() + \"/\" + path\n",
    "    \n",
    "    print(f\"Searching folder at {path} for photo of {your_name}\")\n",
    "\n",
    "if filename == \"\": \n",
    "    filename = [filename for filename in os.listdir(path) \n",
    "                if re.search(re.escape(name) + r'+', filename, re.IGNORECASE)][0] # we use first occurence of name\n",
    "\n",
    "print(f'Using {filename} as reference photo')\n",
    "print(\"If you want a different image used, please specify 'filename' variable\")\n",
    "\n",
    "image = Image.open(path + \"/\" + filename) # load image\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the right person to the right size\n",
    "First, we want to crop the image to focus on the person who graduated\n",
    "\n",
    "This step is to ensure the only person in focus is the person who just graduated. Here, \n",
    "- The image is resized to only contain upperbody to ensure consistency (if multiple faces are available, you will have to choose what face to focus on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# face rec code from: https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m face_cascade \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(\u001b[39m'\u001b[39m\u001b[39mmodels/haarcascade_frontalface_default.xml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gray_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(np\u001b[39m.\u001b[39marray(image), cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39mdetectMultiScale(gray_img, \u001b[39m1.1\u001b[39m, \u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# face rec code from: https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "gray_img = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(faces) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m: \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMultiple faces detected! Please help determine what face to focus on by changing the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mface_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m variable \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(faces) > 1: \n",
    "    print(\"Multiple faces detected! Please help determine what face to focus on by changing the 'face_index' variable \")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    text_kwargs = dict(ha='left', va='top', fontsize=28, color='r')\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        plt.text(x,y, i, **text_kwargs)\n",
    "    # ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    face_index = 1 # change here if multiple faces are detected\n",
    "elif len(faces) == 1: \n",
    "    face_index = 0\n",
    "else: \n",
    "    print(\"No faces detected, skipping final cropping \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x, y, w, h \u001b[39m=\u001b[39m faces[face_index]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m w \u001b[39m>\u001b[39m h:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     measure \u001b[39m=\u001b[39m w\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "x, y, w, h = faces[face_index]\n",
    "\n",
    "if w > h:\n",
    "    measure = w\n",
    "else: \n",
    "    measure = h \n",
    "\n",
    "\n",
    "x_min = x-measure*1.25 if x-measure*1.25 > 0 else 0\n",
    "x_max = x_min+3.5*measure if x_min+3.5*measure < image.width else image.width\n",
    "y_min = y-measure if y-measure > 0 else 0\n",
    "y_max = y_min+3.5*measure if y_min+3.5*measure < image.height else image.height\n",
    "\n",
    "cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(cropped_image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing background \n",
    "\n",
    "For removing background we suggest using using the website [remove.bg](https://www.remove.bg/), which provides the best found results. \n",
    "\n",
    "Simply export the cropped image and specify the path to the modified image afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cropped_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Exporting cropped image\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cropped_image\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPictures/cropped/cropped_image_\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cropped_image' is not defined"
     ]
    }
   ],
   "source": [
    "# Exporting cropped image\n",
    "cropped_image.save(f'Pictures/cropped/cropped_image_{name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vap/Downloads/cropped_image_someoneclever-removebg-preview.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Importing image \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m background_removed \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/home/vap/Downloads/cropped_image_\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-removebg-preview.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m4\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(background_removed)\n",
      "File \u001b[0;32m~/miniconda3/envs/phd/lib/python3.11/site-packages/PIL/Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3215\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3217\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3218\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3219\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vap/Downloads/cropped_image_someoneclever-removebg-preview.png'"
     ]
    }
   ],
   "source": [
    "# Importing image \n",
    "background_removed = Image.open(f\"/home/vap/Downloads/cropped_image_{name}-removebg-preview.png\")\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(background_removed)\n",
    "plt.axis('off')\n",
    "\n",
    "final_image = background_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting\n",
    "Inpainting is entirely voluntary, but is suggested if parts of the person is missing. Furthermore, you may choose to use inpainting to remove distracting objects from the photo or to edit outfits or stances (with varying quality)\n",
    "\n",
    "First, all necessary components are installed to perform inpaitning using library [\"latent diffusion\"](https://github.com/CompVis/latent-diffusion)\n",
    "\n",
    "First, a user interface lets to mark the area, where you want to perform inpainting\n",
    "\n",
    "Second, inpainting is performed from the latent_diffussion library itself. The step needed for performing inpainting are described below. This is done in a different enviroment due to dependency issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'background_removed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 20\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m root \u001b[39m=\u001b[39m tk\u001b[39m.\u001b[39mTk()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m app \u001b[39m=\u001b[39m MaskUI(root)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m app\u001b[39m.\u001b[39mload_image(background_removed\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m root\u001b[39m.\u001b[39mmainloop()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mask \u001b[39m=\u001b[39m app\u001b[39m.\u001b[39mmask\n",
      "\u001b[0;31mNameError\u001b[0m: name 'background_removed' is not defined"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tools.mask_ui as mask_ui\n",
    "importlib.reload(mask_ui) # ensures that change in tools/mask_ui.py are loaded\n",
    "\n",
    "from tools.mask_ui import MaskUI\n",
    "\n",
    "root = tk.Tk()\n",
    "app = MaskUI(root)\n",
    "app.load_image(background_removed.copy())\n",
    "root.mainloop()\n",
    "\n",
    "mask = app.mask\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take ratio aspect into consideration\n",
    "input_img = resize_wrt_ratio(background_removed, 512)\n",
    "input_mask = resize_wrt_ratio(mask, 512)\n",
    "\n",
    "# editing input_img to not be transparent, as latentdiffusion does not work well with transparent images \n",
    "bg = Image.new(mode = \"RGB\", size = (512,512),\n",
    "               color = (200, 200, 200)) # If you change background on poster, remember to also change this\n",
    "bg.paste(input_img, (266-int(input_img.width/2),0), mask=input_img)\n",
    "input_img = bg\n",
    "\n",
    "bg = Image.new(mode = \"RGB\", size = (512,512),\n",
    "               color = (0, 0, 0)) # If you change background on poster, remember to also change this\n",
    "bg.paste(input_mask, (266-int(input_mask.width/2),0))\n",
    "input_mask =  bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'latentdiffusion'...\n",
      "remote: Enumerating objects: 341, done.\u001b[K\n",
      "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
      "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
      "remote: Total 341 (delta 116), reused 107 (delta 107), pack-reused 169\u001b[K\n",
      "Receiving objects: 100% (341/341), 28.69 MiB | 6.87 MiB/s, done.\n",
      "Resolving deltas: 100% (148/148), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/CompVis/latent-diffusion latentdiffusion\n",
    "! rm latentdiffusion/data/inpainting_examples/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img.save(f'latentdiffusion/data/inpainting_examples/{name}.png')\n",
    "input_mask.save(f'latentdiffusion/data/inpainting_examples/{name}_mask.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing inpainting with latent_diffusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the steps from their [github](https://github.com/CompVis/latent-diffusion), and add a few more to combat some dependency issues. Run the below commands in your terminal from the root PhD_Image folder or cd right into latentdiffusion\n",
    "\n",
    "If you want to rerun inpainting (eg. if you're unhappy with the results), simple run the last command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1054697258.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    wget -O models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "#### RUN IN TERMINAL\n",
    "\n",
    "cd latentdiffusion\n",
    "\n",
    "# Init environment \n",
    "conda env create -f environment.yaml\n",
    "conda activate ldm\n",
    "pip install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.5.0 # we use 0.5.0 instead of 0.6.0\n",
    "pip install git+https://github.com/arogozhnikov/einops.git\n",
    "# pip install omegae\n",
    "\n",
    "# to fix local dep issues\n",
    "pip install pytorch-lightning==1.6.5\n",
    "pip install chardet\n",
    "\n",
    "# we then download the models \n",
    "mkdir -p models/rdm/rdm768x768/\n",
    "wget -O models/rdm/rdm768x768/model.ckpt https://ommer-lab.com/files/rdm/model.ckpt\n",
    "wget -O models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1\n",
    "\n",
    "# running inpainting\n",
    "\n",
    "sed -i -e 's/from torch._six/# from torch._six/g' src/taming-transformers/taming/data/utils.py # to remove deprecated function thats not being used anyway \n",
    "python scripts/inpaint.py --indir data/inpainting_examples/ --outdir outputs/inpainting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vap/Documents/poster-generator/create_poster.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatentdiffusion/outputs/inpainting_results/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m final_image \u001b[39m=\u001b[39m results\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vap/Documents/poster-generator/create_poster.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "results = Image.open(f'latentdiffusion/outputs/inpainting_results/{name}.png')\n",
    "final_image = results\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(results)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating poster\n",
    "We are finally ready to create the poster, which will go up on the Wall of Fame. Once done, print out the a4 pdf and you will have your picture ready for framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing image to fit unto poster\n",
    "graduation_photo = final_image.copy()\n",
    "desired_height = 1100 # we want pictures to be same height, varying widths \n",
    "\n",
    "\n",
    "graduation_photo = resize_wrt_ratio(graduation_photo, desired_height)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
    "from textwrap import wrap\n",
    "\n",
    "edge = Image.new(mode = \"RGB\", size = (1870, 2620), \n",
    "                        color = (200,200,200) ) \n",
    "\n",
    "poster = Image.new(mode = \"RGB\", size = (1860, 2610), # size as the used frames (A5 size 1748,2480)\n",
    "                        #    color = (102, 102, 102)) # grey\n",
    "                        # color = (84, 97, 110)) # dusty aalborg blue\n",
    "                        color = (255,255,255) ) # white\n",
    "\n",
    "edge.paste(poster,((5,5))) # adding edge to the poster is easier to cut from white paper \n",
    "poster = edge\n",
    "\n",
    "font_color = (33,26,82)\n",
    "font_size = 80\n",
    "# Add text to image\n",
    "draw = ImageDraw.Draw(poster)\n",
    "draw.fill = 'white'\n",
    "draw.font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=80)\n",
    "\n",
    "# add classic aau background waves\n",
    "aau_waves = Image.open('Poster/Requirements/AAU_BOELGER_RGB-03.png')\n",
    "aau_waves = aau_waves.resize((1860, 2610))\n",
    "aau_waves = aau_waves.convert('LA').convert('RGBA') # converting to grayscale wrt transparency \n",
    "aau_waves2 = aau_waves.copy()\n",
    "aau_waves2.putalpha(20)\n",
    "aau_waves.paste(aau_waves2, aau_waves)\n",
    "poster.paste(aau_waves, (0,0), mask=aau_waves)\n",
    "\n",
    "\n",
    "# PHD NAME\n",
    "# textpos_width, textpos_height = (poster.width/2, textpos_height+(i+1.5)*90)\n",
    "textpos_width, textpos_height = (poster.width/2, 250)\n",
    "name_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size)\n",
    "msg = your_name \n",
    "draw.text(((textpos_width),textpos_height), msg.upper(), anchor=\"ms\", font=name_font,fill=font_color)\n",
    "\n",
    "\n",
    "# add modified picture of person and frame\n",
    "image_height_placement = 400\n",
    "frame_width = 0\n",
    "edge_width = 6 # even number please\n",
    "\n",
    "# frame border\n",
    "frame = Image.new(mode = \"RGB\", \n",
    "                   size = (graduation_photo.height+frame_width+edge_width, graduation_photo.height+frame_width+edge_width),  \n",
    "                #    color = (150, 150, 150))\n",
    "                color=font_color)\n",
    "poster.paste(frame, ((poster.width//2) - (frame.width//2), image_height_placement-int(frame_width/2+edge_width/2)))\n",
    "# frame\n",
    "frame = Image.new(mode = \"RGB\", \n",
    "                   size = (graduation_photo.height+frame_width, graduation_photo.height+frame_width),  \n",
    "                   color = (200, 200, 200))\n",
    "poster.paste(frame, ((poster.width//2) - (frame.width//2), image_height_placement-(int(frame_width/2))))\n",
    "#image\n",
    "try: \n",
    "    poster.paste(graduation_photo, ((poster.width//2) - (graduation_photo.width//2), image_height_placement), mask=graduation_photo)\n",
    "except: \n",
    "    poster.paste(graduation_photo, ((poster.width//2) - (graduation_photo.width//2), image_height_placement))\n",
    "\n",
    "# TITLE\n",
    "# textpos_width, textpos_height = (poster.width/2, 1550)\n",
    "textpos_width, textpos_height = (poster.width/2, 1700)\n",
    "title_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size)\n",
    "for i, line in enumerate(wrap(phd_title, 30)): # second arg in wrap: max number of chars per line\n",
    "    draw.text(((textpos_width),textpos_height + i*(font_size+10)), line.upper(), anchor=\"ms\", font=title_font,fill=font_color)\n",
    "\n",
    "\n",
    "# PHD DEFENCE DATE\n",
    "textpos_width, textpos_height = (poster.width/2, textpos_height+(i+1.5)*(font_size+10))\n",
    "# textpos_width, textpos_height = (poster.width/2, textpos_height+100)\n",
    "date_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size-20)\n",
    "msg = \"Ph.D Defense \" + date_of_graduation\n",
    "draw.text(((textpos_width),textpos_height), msg, anchor=\"ms\", font=date_font,fill=font_color)\n",
    "\n",
    "\n",
    "#  AAU + VAPLAB Logo\n",
    "aau_logo = Image.open('Poster/Requirements/__AAU_CENTER_RGB.png')\n",
    "aau_logo.thumbnail((200,200))\n",
    "poster.paste(aau_logo, (poster.width//2 - aau_logo.width//2, poster.height - aau_logo.height - 100), mask=aau_logo)\n",
    "\n",
    "# textpos_width, textpos_height = (poster.width/2, 50)\n",
    "# vap_font = ImageFont.truetype('Poster/Barlow-Black.ttf', size=23)\n",
    "# draw.text(((textpos_width),textpos_height), \"V i s u a l   A n a l y s i s   a n d \".upper(), anchor=\"ms\", font=vap_font)\n",
    "# draw.text(((textpos_width),textpos_height+30), \"P e r c e p t i o n   L a b\".upper(), anchor=\"ms\", font=vap_font)\n",
    "\n",
    "# display(poster)\n",
    "poster.save(f\"Poster/Outputs/poster_{name}.png\")\n",
    "poster.save(f\"Poster/Outputs/poster_{name}_a5.pdf\")\n",
    "\n",
    "a4_doc = Image.new(mode = \"RGB\", size = (2480, 3508), # A4 size\n",
    "                           color = (255, 255, 255))\n",
    "\n",
    "a4_doc.paste(poster, (200,200))\n",
    "a4_doc.save(f\"Poster/Outputs/poster_{name}_a4.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you're done, congrats! \n",
    "\n",
    "You can print the poster_{name}_a4 pdf, and you get a picture that fits the frames perfectly :))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For future developers of this script: \n",
    "Hi and welcome to this task! To help you determine what areas needs improvements, I have written out solutions that have already been looked into or tested,  but did not make the cut\n",
    "\n",
    "### For removing background: \n",
    "- Python library *rembg* was used, but did not remove background as well as remove.bg (but unlike remove.bg, it does not degrade the image). Furthermore, the dependencies for *rembg* clashes massively with the rest of the dependencies\n",
    "\n",
    "### For inpainting\n",
    "- *Generative_inpainting_pytorch* did not produce good results\n",
    "\n",
    "The current solution, *latent_diffusion* does not produce super good results either, but it was the best solution found, that does not exist behind a paywall \n",
    "\n",
    "### For fixing postures \n",
    "- *Coordinate_based_inpainting* was investigated, but requires a UV map of each person (thus scratched)\n",
    "- *DragGAN* was looked into, but due to dependency clashes between NVIDIA and ninja build, it was not used. \n",
    "\n",
    "### For creating poster\n",
    "- Python library *docx* was previously used for creating a word document instead of an image, but it was not possible to add a background image, and thus this solution was scratched\n",
    "- *Niceposter* was considered, but it was deemed that there wasn't enough options to create the poster we wanted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
