{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello and congrats on the phd!!\n",
    "This notebook will help you streamline your graduation photo according to the rest of team VAP-lab. The code should be light weight, with the exception of the inpainting tool, which is voluntary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to install the requirements. Please make sure you have conda installed and run the following commands in *your terminal* and make sure your notebook is running on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RRun in terminal, not in notebook \n",
    "conda env create -f environment.yml\n",
    "conda activate phd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running cells in the notebook, you should run them through the newly created 'phd' kernel. You may verify that you are running the notebook in the correct environment if the following code outputs an environment at location \"envs/phd\". \n",
    "\n",
    "If the environemnt is not available, try shutting down you editor and opening it again (you just got a PhD, and we still resolve to turning this on and off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda list | grep \"packages in environment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things smoother, please help define the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = \"Someone clever\" # As you would want on your poster\n",
    "phd_title = \"Something very smart and very groundbreaking\"\n",
    "date_of_graduation = \"DD-MM-YYYY\" # format: DD-MM-YYYY\n",
    "path_to_image = \"Pictures/\" # Folder, where your photo is located\n",
    "filename = \"\" # if you want to specify what photo to use, if multiple are available. Otherwise leave blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook contains methods for \n",
    "- Cropping the image\n",
    "- Removing background (although we recommend using www.remove.bg for complex cases)\n",
    "\n",
    "- Inpainting for creating missing details or removing various items (voluntary)\n",
    "\n",
    "And finally creating the actual pdf which will go on the Wall of Fame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "Please run the cells below to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os, re\n",
    "from PIL import Image, ImageOps\n",
    "import tkinter as tk # for UIs *\n",
    "import cv2 # for face detection\n",
    "\n",
    "def resize_wrt_ratio(img, desired_height): \n",
    "    ratio = img.width/img.height\n",
    "\n",
    "    img = img.resize((int(desired_height*ratio), desired_height))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = your_name.replace(\" \", \"\").lower()\n",
    "path = path_to_image\n",
    "\n",
    "\n",
    "if type(path) == type(None) or path == \"\":\n",
    "    print(f\"Searching current folder for photo of {your_name}\")\n",
    "else: \n",
    "    path = os.getcwd() + \"/\" + path\n",
    "    \n",
    "    print(f\"Searching folder at {path} for photo of {your_name}\")\n",
    "\n",
    "if filename == \"\": \n",
    "    filename = [filename for filename in os.listdir(path) \n",
    "                if re.search(re.escape(name) + r'+', filename, re.IGNORECASE)][0] # we use first occurence of name\n",
    "\n",
    "print(f'Using {filename} as reference photo')\n",
    "print(\"If you want a different image used, please specify 'filename' variable\")\n",
    "\n",
    "image = Image.open(path + \"/\" + filename) # load image\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above fails, it's likely because we are looking for photos, whose titles contains your name. Simply specify *filename* if you want to avoid renaming your photo (otherwise make sure that the name of your photo contains your full name with no spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the right person to the right size\n",
    "First, we want to crop the image to focus on the person who graduated\n",
    "\n",
    "This step is to ensure the only person in focus is the person who just graduated. Here, \n",
    "- The image is resized to only contain upperbody to ensure consistency (if multiple faces are available, you will have to choose what face to focus on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face rec code from: https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "gray_img = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(faces) > 1: \n",
    "    print(\"Multiple faces detected! Please help determine what face to focus on by changing the 'face_index' variable \")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    text_kwargs = dict(ha='left', va='top', fontsize=28, color='r')\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        plt.text(x,y, i, **text_kwargs)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    face_index = 1 # change here if multiple faces are detected\n",
    "elif len(faces) == 1: \n",
    "    face_index = 0\n",
    "else: \n",
    "    print(\"No faces detected, skipping final cropping \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = faces[face_index]\n",
    "\n",
    "if w > h:\n",
    "    measure = w\n",
    "else: \n",
    "    measure = h \n",
    "\n",
    "\n",
    "x_min = x-measure*1.25 if x-measure*1.25 > 0 else 0\n",
    "x_max = x_min+3.5*measure if x_min+3.5*measure < image.width else image.width\n",
    "y_min = y-measure if y-measure > 0 else 0\n",
    "y_max = y_min+3.5*measure if y_min+3.5*measure < image.height else image.height\n",
    "\n",
    "cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(cropped_image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing background \n",
    "\n",
    "For removing background we suggest using using the website [remove.bg](https://www.remove.bg/), which provides the best found results. \n",
    "\n",
    "Simply export the cropped image and specify the path to the modified image afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting cropped image\n",
    "cropped_image.save(f'Pictures/cropped/cropped_image_{name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing image \n",
    "background_removed = Image.open(f\"/home/vap/Downloads/cropped_image_{name}-removebg-preview.png\")\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(background_removed)\n",
    "plt.axis('off')\n",
    "\n",
    "final_image = background_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting\n",
    "Inpainting is entirely voluntary, but is suggested if parts of the person is missing. Furthermore, you may choose to use inpainting to remove distracting objects from the photo or to edit outfits or stances (with varying quality)\n",
    "\n",
    "First, all necessary components are installed to perform inpaitning using library [\"latent diffusion\"](https://github.com/CompVis/latent-diffusion)\n",
    "\n",
    "First, a user interface lets to mark the area, where you want to perform inpainting\n",
    "\n",
    "Second, inpainting is performed from the latent_diffussion library itself. The step needed for performing inpainting are described below. This is done in a different enviroment due to dependency issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tools.mask_ui as mask_ui\n",
    "importlib.reload(mask_ui) # ensures that change in tools/mask_ui.py are loaded\n",
    "\n",
    "from tools.mask_ui import MaskUI\n",
    "\n",
    "root = tk.Tk()\n",
    "app = MaskUI(root)\n",
    "app.load_image(background_removed.copy())\n",
    "root.mainloop()\n",
    "\n",
    "mask = app.mask\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take ratio aspect into consideration\n",
    "input_img = resize_wrt_ratio(background_removed, 512)\n",
    "input_mask = resize_wrt_ratio(mask, 512)\n",
    "\n",
    "# editing input_img to not be transparent, as latentdiffusion does not work well with transparent images \n",
    "bg = Image.new(mode = \"RGB\", size = (512,512),\n",
    "               color = (200, 200, 200)) # If you change background on poster, remember to also change this\n",
    "bg.paste(input_img, (266-int(input_img.width/2),0), mask=input_img)\n",
    "input_img = bg\n",
    "\n",
    "bg = Image.new(mode = \"RGB\", size = (512,512),\n",
    "               color = (0, 0, 0)) # If you change background on poster, remember to also change this\n",
    "bg.paste(input_mask, (266-int(input_mask.width/2),0))\n",
    "input_mask =  bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/CompVis/latent-diffusion latentdiffusion\n",
    "! rm latentdiffusion/data/inpainting_examples/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img.save(f'latentdiffusion/data/inpainting_examples/{name}.png')\n",
    "input_mask.save(f'latentdiffusion/data/inpainting_examples/{name}_mask.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing inpainting with latent_diffusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the steps from their [github](https://github.com/CompVis/latent-diffusion), and add a few more to combat some dependency issues. Run the below commands in your terminal from the root PhD_Image folder or cd right into latentdiffusion\n",
    "\n",
    "If you want to rerun inpainting (eg. if you're unhappy with the results), simple run the last command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#### RUN IN TERMINAL\n",
    "\n",
    "cd latentdiffusion\n",
    "\n",
    "# Init environment \n",
    "conda env create -f environment.yaml\n",
    "conda activate ldm\n",
    "pip install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.5.0 # we use 0.5.0 instead of 0.6.0\n",
    "pip install git+https://github.com/arogozhnikov/einops.git\n",
    "# pip install omegae\n",
    "\n",
    "# to fix local dep issues\n",
    "pip install pytorch-lightning==1.6.5\n",
    "pip install chardet\n",
    "\n",
    "# we then download the models \n",
    "mkdir -p models/rdm/rdm768x768/\n",
    "wget -O models/rdm/rdm768x768/model.ckpt https://ommer-lab.com/files/rdm/model.ckpt\n",
    "wget -O models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1\n",
    "\n",
    "# running inpainting\n",
    "\n",
    "sed -i -e 's/from torch._six/# from torch._six/g' src/taming-transformers/taming/data/utils.py # to remove deprecated function thats not being used anyway \n",
    "python scripts/inpaint.py --indir data/inpainting_examples/ --outdir outputs/inpainting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Image.open(f'latentdiffusion/outputs/inpainting_results/{name}.png')\n",
    "final_image = results\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(results)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating poster\n",
    "We are finally ready to create the poster, which will go up on the Wall of Fame. Once done, print out the a4 pdf and you will have your picture ready for framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing image to fit unto poster\n",
    "graduation_photo = final_image.copy()\n",
    "desired_height = 1100 # we want pictures to be same height, varying widths \n",
    "\n",
    "\n",
    "graduation_photo = resize_wrt_ratio(graduation_photo, desired_height)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
    "from textwrap import wrap\n",
    "\n",
    "edge = Image.new(mode = \"RGB\", size = (1870, 2620), \n",
    "                        color = (200,200,200) ) \n",
    "\n",
    "poster = Image.new(mode = \"RGB\", size = (1860, 2610), # size as the used frames (A5 size 1748,2480)\n",
    "                        #    color = (102, 102, 102)) # grey\n",
    "                        # color = (84, 97, 110)) # dusty aalborg blue\n",
    "                        color = (255,255,255) ) # white\n",
    "\n",
    "edge.paste(poster,((5,5))) # adding edge to the poster is easier to cut from white paper \n",
    "poster = edge\n",
    "\n",
    "font_color = (33,26,82)\n",
    "font_size = 80\n",
    "# Add text to image\n",
    "draw = ImageDraw.Draw(poster)\n",
    "draw.fill = 'white'\n",
    "draw.font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=80)\n",
    "\n",
    "# add classic aau background waves\n",
    "aau_waves = Image.open('Poster/Requirements/AAU_BOELGER_RGB-03.png')\n",
    "aau_waves = aau_waves.resize((1860, 2610))\n",
    "aau_waves = aau_waves.convert('LA').convert('RGBA') # converting to grayscale wrt transparency \n",
    "aau_waves2 = aau_waves.copy()\n",
    "aau_waves2.putalpha(20)\n",
    "aau_waves.paste(aau_waves2, aau_waves)\n",
    "poster.paste(aau_waves, (0,0), mask=aau_waves)\n",
    "\n",
    "\n",
    "# PHD NAME\n",
    "# textpos_width, textpos_height = (poster.width/2, textpos_height+(i+1.5)*90)\n",
    "textpos_width, textpos_height = (poster.width/2, 250)\n",
    "name_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size)\n",
    "msg = your_name \n",
    "draw.text(((textpos_width),textpos_height), msg.upper(), anchor=\"ms\", font=name_font,fill=font_color)\n",
    "\n",
    "\n",
    "# add modified picture of person and frame\n",
    "image_height_placement = 400\n",
    "frame_width = 0\n",
    "edge_width = 6 # even number please\n",
    "\n",
    "# frame border\n",
    "frame = Image.new(mode = \"RGB\", \n",
    "                   size = (graduation_photo.height+frame_width+edge_width, graduation_photo.height+frame_width+edge_width),  \n",
    "                #    color = (150, 150, 150))\n",
    "                color=font_color)\n",
    "poster.paste(frame, ((poster.width//2) - (frame.width//2), image_height_placement-int(frame_width/2+edge_width/2)))\n",
    "# frame\n",
    "frame = Image.new(mode = \"RGB\", \n",
    "                   size = (graduation_photo.height+frame_width, graduation_photo.height+frame_width),  \n",
    "                   color = (200, 200, 200))\n",
    "poster.paste(frame, ((poster.width//2) - (frame.width//2), image_height_placement-(int(frame_width/2))))\n",
    "#image\n",
    "try: \n",
    "    poster.paste(graduation_photo, ((poster.width//2) - (graduation_photo.width//2), image_height_placement), mask=graduation_photo)\n",
    "except: \n",
    "    poster.paste(graduation_photo, ((poster.width//2) - (graduation_photo.width//2), image_height_placement))\n",
    "\n",
    "# TITLE\n",
    "# textpos_width, textpos_height = (poster.width/2, 1550)\n",
    "textpos_width, textpos_height = (poster.width/2, 1700)\n",
    "title_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size)\n",
    "for i, line in enumerate(wrap(phd_title, 30)): # second arg in wrap: max number of chars per line\n",
    "    draw.text(((textpos_width),textpos_height + i*(font_size+10)), line.upper(), anchor=\"ms\", font=title_font,fill=font_color)\n",
    "\n",
    "\n",
    "# PHD DEFENCE DATE\n",
    "textpos_width, textpos_height = (poster.width/2, textpos_height+(i+1.5)*(font_size+10))\n",
    "# textpos_width, textpos_height = (poster.width/2, textpos_height+100)\n",
    "date_font = ImageFont.truetype('Poster/Requirements/Barlow-Medium.ttf', size=font_size-20)\n",
    "msg = \"Ph.D Defense \" + date_of_graduation\n",
    "draw.text(((textpos_width),textpos_height), msg, anchor=\"ms\", font=date_font,fill=font_color)\n",
    "\n",
    "\n",
    "#  AAU + VAPLAB Logo\n",
    "aau_logo = Image.open('Poster/Requirements/__AAU_CENTER_RGB.png')\n",
    "aau_logo.thumbnail((200,200))\n",
    "poster.paste(aau_logo, (poster.width//2 - aau_logo.width//2, poster.height - aau_logo.height - 100), mask=aau_logo)\n",
    "\n",
    "# textpos_width, textpos_height = (poster.width/2, 50)\n",
    "# vap_font = ImageFont.truetype('Poster/Barlow-Black.ttf', size=23)\n",
    "# draw.text(((textpos_width),textpos_height), \"V i s u a l   A n a l y s i s   a n d \".upper(), anchor=\"ms\", font=vap_font)\n",
    "# draw.text(((textpos_width),textpos_height+30), \"P e r c e p t i o n   L a b\".upper(), anchor=\"ms\", font=vap_font)\n",
    "\n",
    "# display(poster)\n",
    "poster.save(f\"Poster/Outputs/poster_{name}.png\")\n",
    "poster.save(f\"Poster/Outputs/poster_{name}_a5.pdf\")\n",
    "\n",
    "a4_doc = Image.new(mode = \"RGB\", size = (2480, 3508), # A4 size\n",
    "                           color = (255, 255, 255))\n",
    "\n",
    "a4_doc.paste(poster, (200,200))\n",
    "a4_doc.save(f\"Poster/Outputs/poster_{name}_a4.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you're done, congrats! \n",
    "\n",
    "You can print the poster_{name}_a4 pdf, and you get a picture that fits the frames perfectly :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For future developers of this script: \n",
    "Hi and welcome to this task! To help you determine what areas needs improvements, I have written out solutions that have already been looked into or tested,  but did not make the cut\n",
    "\n",
    "### For removing background: \n",
    "- Python library *rembg* was used, but did not remove background as well as remove.bg (but unlike remove.bg, it does not degrade the image). Furthermore, the dependencies for *rembg* clashes massively with the rest of the dependencies\n",
    "\n",
    "### For inpainting\n",
    "- *Generative_inpainting_pytorch* did not produce good results\n",
    "\n",
    "The current solution, *latent_diffusion* does not produce super good results either, but it was the best solution found, that does not exist behind a paywall \n",
    "\n",
    "### For fixing postures \n",
    "- *Coordinate_based_inpainting* was investigated, but requires a UV map of each person (thus scratched)\n",
    "- *DragGAN* was looked into, but due to dependency clashes between NVIDIA and ninja build, it was not used. \n",
    "\n",
    "### For creating poster\n",
    "- Python library *docx* was previously used for creating a word document instead of an image, but it was not possible to add a background image, and thus this solution was scratched\n",
    "- *Niceposter* was considered, but it was deemed that there wasn't enough options to create the poster we wanted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
